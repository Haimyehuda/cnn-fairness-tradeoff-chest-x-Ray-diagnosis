{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Fairness Metrics + Plot (Colab)\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LOAD MODEL + TEST DATA\n",
    "# -------------------------------\n",
    "from common.dataset import load_imbalanced_cifar\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from common.model import SimpleCNN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = load_imbalanced_cifar(cat_count=30, dog_count=500)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "_, test_ds = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"/content/model.pth\"))  # עדכן נתיב אם צריך\n",
    "model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# 2. COLLECT PREDICTIONS\n",
    "# -------------------------------\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        y_prob.extend(probs[:, 1].cpu().numpy())\n",
    "        y_pred.extend(torch.argmax(outputs, 1).cpu().numpy())\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. GROUP MASKS\n",
    "# 0 = Cats  |  1 = Dogs\n",
    "# -------------------------------\n",
    "\n",
    "group_A = y_true == 0\n",
    "group_B = y_true == 1\n",
    "\n",
    "# -------------------------------\n",
    "# 4. METRIC FUNCTIONS\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "def demographic_parity(preds, mask):\n",
    "    return np.mean(preds[mask] == 1)\n",
    "\n",
    "\n",
    "def tpr(true, pred, mask):\n",
    "    tp = np.sum((true[mask] == 1) & (pred[mask] == 1))\n",
    "    p = np.sum(true[mask] == 1)\n",
    "    return tp / p if p > 0 else 0\n",
    "\n",
    "\n",
    "def fpr(true, pred, mask):\n",
    "    fp = np.sum((true[mask] == 0) & (pred[mask] == 1))\n",
    "    n = np.sum(true[mask] == 0)\n",
    "    return fp / n if n > 0 else 0\n",
    "\n",
    "\n",
    "def accuracy(true, pred, mask):\n",
    "    return np.mean(true[mask] == pred[mask])\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 5. COMPUTE METRICS\n",
    "# -------------------------------\n",
    "\n",
    "metrics = {\n",
    "    \"DP (Demographic Parity)\": [\n",
    "        demographic_parity(y_pred, group_A),\n",
    "        demographic_parity(y_pred, group_B),\n",
    "    ],\n",
    "    \"TPR (Equal Opportunity)\": [\n",
    "        tpr(y_true, y_pred, group_A),\n",
    "        tpr(y_true, y_pred, group_B),\n",
    "    ],\n",
    "    \"FPR (Equalized Odds)\": [\n",
    "        fpr(y_true, y_pred, group_A),\n",
    "        fpr(y_true, y_pred, group_B),\n",
    "    ],\n",
    "    \"Accuracy per Group\": [\n",
    "        accuracy(y_true, y_pred, group_A),\n",
    "        accuracy(y_true, y_pred, group_B),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 6. PLOT\n",
    "# -------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metric_names = list(metrics.keys())\n",
    "index = np.arange(len(metric_names))\n",
    "bar_width = 0.35\n",
    "\n",
    "A_vals = [metrics[m][0] for m in metric_names]\n",
    "B_vals = [metrics[m][1] for m in metric_names]\n",
    "\n",
    "ax.bar(index, A_vals, bar_width, label=\"Group A (Cats)\")\n",
    "ax.bar(index + bar_width, B_vals, bar_width, label=\"Group B (Dogs)\")\n",
    "\n",
    "ax.set_xlabel(\"Metric\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"Fairness Metrics by Group (Empirical Results)\")\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(metric_names, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
